{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Colab-specific setup\n",
    "!(stat -t /usr/local/lib/*/dist-packages/google/colab > /dev/null 2>&1) && exit \n",
    "pip install yacs 2>&1 >> install.log\n",
    "git init 2>&1 >> install.log\n",
    "git remote add origin https://github.com/davidbau/semantic-segmentation-pytorch.git 2>&1 >> install.log\n",
    "git pull origin tutorial 2>&1 >> install.log\n",
    "DOWNLOAD_ONLY=1 ./demo_test.sh 2>&1 >> install.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System libs\n",
    "import os\n",
    "import argparse\n",
    "from distutils.version import LooseVersion\n",
    "# Numerical libs\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from scipy.io import loadmat\n",
    "import csv\n",
    "# Our libs\n",
    "from mit_semseg.dataset import TestDataset\n",
    "from mit_semseg.models import ModelBuilder, SegmentationModule\n",
    "from mit_semseg.utils import colorEncode\n",
    "from mit_semseg.lib.nn import user_scattered_collate, async_copy_to\n",
    "from mit_semseg.lib.utils import as_numpy\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from mit_semseg.config import cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = loadmat('data/color150.mat')['colors']\n",
    "names = {}\n",
    "with open('data/object150_info.csv') as f:\n",
    "    reader = csv.reader(f)\n",
    "    next(reader)\n",
    "    for row in reader:\n",
    "        names[int(row[0])] = row[5].split(\";\")[0]\n",
    "\n",
    "\n",
    "def visualize_result(data, pred):\n",
    "    (img, info) = data\n",
    "\n",
    "    # colorize prediction\n",
    "    pred_color = colorEncode(pred, colors).astype(np.uint8)\n",
    "\n",
    "    # aggregate images and save\n",
    "    im_vis = np.concatenate((img, pred_color), axis=1)\n",
    "    display(Image.fromarray(im_vis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network Builders\n",
    "net_encoder = ModelBuilder.build_encoder(\n",
    "    arch='resnet50dilated',\n",
    "    fc_dim=2048,\n",
    "    weights='ckpt/ade20k-resnet50dilated-ppm_deepsup/encoder_epoch_20.pth')\n",
    "net_decoder = ModelBuilder.build_decoder(\n",
    "    arch='ppm_deepsup',\n",
    "    fc_dim=2048,\n",
    "    num_class=150,\n",
    "    weights='ckpt/ade20k-resnet50dilated-ppm_deepsup/decoder_epoch_20.pth',\n",
    "    use_softmax=True)\n",
    "\n",
    "crit = nn.NLLLoss(ignore_index=-1)\n",
    "\n",
    "segmentation_module = SegmentationModule(net_encoder, net_decoder, crit)\n",
    "segmentation_module.eval()\n",
    "segmentation_module.cuda()\n",
    "\n",
    "# Dataset\n",
    "dataset_test = TestDataset(\n",
    "    [{'fpath_img': 'ADE_val_00001519.jpg'}], cfg.DATASET)\n",
    "\n",
    "singleton_batch = {'img_data': dataset_test[0]['img_data'][4].cuda()}\n",
    "with torch.no_grad():\n",
    "    scores = segmentation_module(singleton_batch, segSize=dataset_test[0]['img_ori'].shape[:2])\n",
    "_, pred = torch.max(scores, dim=1)\n",
    "visualize_result(\n",
    "      (dataset_test[0]['img_ori'], dataset_test[0]['info']),\n",
    "      pred.cpu()[0].numpy()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following code averages segmenter scores at multiple resolutions for better results\n",
    "def test(segmentation_module, loader, gpu):\n",
    "    segmentation_module.eval()\n",
    "\n",
    "    for batch_data in loader:\n",
    "        # process data\n",
    "        batch_data = batch_data[0]\n",
    "        segSize = (batch_data['img_ori'].shape[0],\n",
    "                   batch_data['img_ori'].shape[1])\n",
    "        img_resized_list = batch_data['img_data']\n",
    "\n",
    "        with torch.no_grad():\n",
    "            scores = torch.zeros(1, cfg.DATASET.num_class, segSize[0], segSize[1])\n",
    "            scores = async_copy_to(scores, gpu)\n",
    "\n",
    "            for img in img_resized_list:\n",
    "                feed_dict = batch_data.copy()\n",
    "                feed_dict['img_data'] = img\n",
    "                del feed_dict['img_ori']\n",
    "                del feed_dict['info']\n",
    "                feed_dict = async_copy_to(feed_dict, gpu)\n",
    "\n",
    "                # forward pass\n",
    "                pred_tmp = segmentation_module(feed_dict, segSize=segSize)\n",
    "                scores = scores + pred_tmp / len(cfg.DATASET.imgSizes)\n",
    "\n",
    "            _, pred = torch.max(scores, dim=1)\n",
    "            pred = as_numpy(pred.squeeze(0).cpu())\n",
    "\n",
    "        # visualization\n",
    "        visualize_result(\n",
    "            (batch_data['img_ori'], batch_data['info']),\n",
    "            pred\n",
    "        )\n",
    "        \n",
    "gpu = 0\n",
    "torch.cuda.set_device(gpu)\n",
    "\n",
    "loader_test = torch.utils.data.DataLoader(\n",
    "    dataset_test,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    collate_fn=user_scattered_collate,\n",
    "    num_workers=5,\n",
    "    drop_last=False)\n",
    "\n",
    "segmentation_module.cuda()\n",
    "\n",
    "test(segmentation_module, loader_test, gpu)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}